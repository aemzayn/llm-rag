# LLM RAG Chatbot - Development Log

## Project Overview

A fullstack LLM chatbot application with document embedding capabilities, user authentication, and role-based access control.

### Tech Stack
- **Frontend**: Next.js 14 (App Router, TypeScript)
- **Backend**: FastAPI (Python)
- **Database**: PostgreSQL + pgvector
- **Embeddings**: sentence-transformers (all-MiniLM-L6-v2)
- **Document Processing**: LangChain + Celery + Redis
- **Authentication**: NextAuth.js + JWT
- **Real-time**: WebSocket
- **Deployment**: Docker Compose

### Key Features
- **Authentication & Authorization**:
  - Superadmin (initial), Admin, Basic User roles
  - Users can sign up, admins promote to admin role
- **Models (Collections)**:
  - Admin creates models with LLM config + documents
  - Group-based access control
  - Flexible LLM providers (Ollama local + API-based with stored keys)
- **Document Management**:
  - Admin uploads PDFs/CSVs (up to 250MB, scalable to 1GB)
  - Background processing with real-time progress via WebSocket
  - Semantic chunking, stored in pgvector
  - Original files stored in Docker volume (toggleable)
- **Chat System**:
  - One active session per user, multiple users per model
  - RAG with source citations
  - Chat history per user
  - Users can upload files in chat

---

## Development Progress

### 2026-01-17

#### ‚úÖ Task 1: Create project structure and initial documentation
**Status**: Completed

**What was done**:
- Created claude.md for tracking development progress
- Created .gitignore, README.md, and .env.example files
- Established project directory structure

**Files created**:
- [claude.md](claude.md)
- [README.md](README.md)
- [.gitignore](.gitignore)
- [.env.example](.env.example)

---

#### ‚úÖ Task 2: Set up Docker Compose for development environment
**Status**: Completed

**What was done**:
- Created docker-compose.yml with all services:
  - PostgreSQL with pgvector extension
  - Redis for caching and Celery queue
  - Ollama for local LLM
  - FastAPI backend
  - Celery worker and beat
  - Next.js frontend
- Configured service dependencies and health checks
- Set up Docker volumes for data persistence

**Files created**:
- [docker-compose.yml](docker-compose.yml)

---

#### ‚úÖ Task 3: Initialize backend (FastAPI) with project structure
**Status**: Completed

**What was done**:
- Created complete backend structure with FastAPI
- Configured SQLAlchemy database models:
  - User model with role-based access (superadmin, admin, user)
  - Model (collection) model with LLM provider configuration
  - Document and DocumentChunk models with pgvector support
  - ChatSession and ChatMessage models
- Set up security with JWT authentication and API key encryption
- Created configuration management with pydantic-settings
- Initialized API route stubs for all endpoints
- Created Celery worker configuration for background tasks
- Set up Alembic for database migrations

**Files created**:
- [backend/requirements.txt](backend/requirements.txt)
- [backend/Dockerfile](backend/Dockerfile)
- [backend/app/main.py](backend/app/main.py)
- [backend/app/core/config.py](backend/app/core/config.py)
- [backend/app/core/security.py](backend/app/core/security.py)
- [backend/app/core/database.py](backend/app/core/database.py)
- [backend/app/models/user.py](backend/app/models/user.py)
- [backend/app/models/model.py](backend/app/models/model.py)
- [backend/app/models/document.py](backend/app/models/document.py)
- [backend/app/models/chat.py](backend/app/models/chat.py)
- [backend/app/api/auth.py](backend/app/api/auth.py)
- [backend/app/api/users.py](backend/app/api/users.py)
- [backend/app/api/models.py](backend/app/api/models.py)
- [backend/app/api/documents.py](backend/app/api/documents.py)
- [backend/app/api/chat.py](backend/app/api/chat.py)
- [backend/app/schemas/user.py](backend/app/schemas/user.py)
- [backend/app/services/user_service.py](backend/app/services/user_service.py)
- [backend/app/workers/celery_app.py](backend/app/workers/celery_app.py)
- [backend/app/workers/tasks.py](backend/app/workers/tasks.py)
- [backend/alembic.ini](backend/alembic.ini)
- [backend/alembic/env.py](backend/alembic/env.py)
- [backend/alembic/script.py.mako](backend/alembic/script.py.mako)

**Key features implemented**:
- Database models with proper relationships
- pgvector integration for embeddings (384 dimensions)
- JWT authentication with access and refresh tokens
- API key encryption using Fernet
- Superadmin auto-initialization on startup
- Celery task structure for document processing

---

#### ‚úÖ Task 4: Initialize frontend (Next.js) with project structure
**Status**: Completed

**What was done**:
- Created Next.js 14 project with App Router
- Set up TypeScript configuration
- Configured TailwindCSS for styling
- Created API client with axios and token management
- Set up TypeScript types for all entities
- Created basic homepage with login/signup links
- Configured environment variables

**Files created**:
- [frontend/package.json](frontend/package.json)
- [frontend/Dockerfile](frontend/Dockerfile)
- [frontend/tsconfig.json](frontend/tsconfig.json)
- [frontend/next.config.js](frontend/next.config.js)
- [frontend/tailwind.config.js](frontend/tailwind.config.js)
- [frontend/postcss.config.js](frontend/postcss.config.js)
- [frontend/.eslintrc.json](frontend/.eslintrc.json)
- [frontend/.env.local.example](frontend/.env.local.example)
- [frontend/src/app/layout.tsx](frontend/src/app/layout.tsx)
- [frontend/src/app/page.tsx](frontend/src/app/page.tsx)
- [frontend/src/app/globals.css](frontend/src/app/globals.css)
- [frontend/src/lib/api.ts](frontend/src/lib/api.ts)
- [frontend/src/types/index.ts](frontend/src/types/index.ts)

**Key features implemented**:
- Axios interceptors for auth token management
- Automatic token refresh on 401 errors
- TypeScript interfaces for all data models
- Dark mode support in CSS
- API client configuration

---

#### ‚úÖ Task 5: Implement authentication system
**Status**: Completed

**What was done**:
- Implemented complete JWT authentication flow
- Created signup endpoint with password validation
- Created login endpoint with credential verification
- Implemented token refresh mechanism
- Created dependency injection for auth protection
- Added role-based access control (RBAC) middleware
- Implemented user management endpoints (CRUD)
- Created frontend login and signup pages
- Added dashboard with user info display
- Integrated toast notifications for user feedback

**Backend files created/updated**:
- [backend/app/core/dependencies.py](backend/app/core/dependencies.py) - Auth dependencies and RBAC
- [backend/app/api/auth.py](backend/app/api/auth.py) - Authentication endpoints (updated)
- [backend/app/api/users.py](backend/app/api/users.py) - User management endpoints (updated)
- [backend/generate_keys.py](backend/generate_keys.py) - Secret key generator

**Frontend files created/updated**:
- [frontend/src/app/login/page.tsx](frontend/src/app/login/page.tsx) - Login page
- [frontend/src/app/signup/page.tsx](frontend/src/app/signup/page.tsx) - Signup page
- [frontend/src/app/dashboard/page.tsx](frontend/src/app/dashboard/page.tsx) - Dashboard
- [frontend/src/app/layout.tsx](frontend/src/app/layout.tsx) - Added toast notifications

**Documentation**:
- [QUICKSTART.md](QUICKSTART.md) - Quick start guide for setup

**Key features implemented**:
- JWT access tokens (30min expiry) and refresh tokens (7 days)
- Secure password hashing with bcrypt
- Token refresh on 401 with automatic retry
- Role-based middleware: `require_admin`, `require_superadmin`
- User CRUD with permission checks
- Prevention of superadmin deletion/demotion
- Frontend auth state management with localStorage
- Automatic redirect on session expiry
- Toast notifications for user feedback

**API Endpoints**:
- POST /api/auth/signup - User registration
- POST /api/auth/login - User login (returns tokens)
- POST /api/auth/refresh - Refresh access token
- GET /api/auth/me - Get current user info
- GET /api/users - List users (Admin only)
- GET /api/users/{id} - Get user (self or admin)
- PATCH /api/users/{id} - Update user (Admin only)
- DELETE /api/users/{id} - Delete user (Admin only)

---

#### ‚úÖ Task 6: Implement model (collection) management
**Status**: Completed

**What was done**:
- Created complete CRUD operations for models
- Implemented model-user access control system
- Added API key encryption for external LLM providers
- Created service layer for model operations
- Implemented user assignment to models
- Added validation for model names and configurations

**Backend files created/updated**:
- [backend/app/schemas/model.py](backend/app/schemas/model.py) - Model Pydantic schemas
- [backend/app/services/model_service.py](backend/app/services/model_service.py) - Model business logic
- [backend/app/api/models.py](backend/app/api/models.py) - Model API endpoints (updated)

**Key features implemented**:
- Model CRUD with LLM provider configuration (Ollama, OpenAI, Anthropic, Custom)
- Encrypted API key storage for external providers
- Group-based access control (assign users to models)
- Admin-only model management
- User access verification for model operations
- Model statistics (user count, document count)

**API Endpoints**:
- POST /api/models - Create model (Admin)
- GET /api/models - List accessible models
- GET /api/models/{id} - Get model details with stats
- PATCH /api/models/{id} - Update model (Admin)
- DELETE /api/models/{id} - Delete model (Admin)
- POST /api/models/{id}/users - Assign users to model (Admin)
- GET /api/models/{id}/users - Get model users (Admin)

---

#### ‚úÖ Task 7: Implement document upload and embedding pipeline
**Status**: Completed

**What was done**:
- Implemented file upload with size validation (up to 250MB)
- Created PDF parser using pypdf
- Created CSV parser using pandas
- Implemented semantic text chunking with LangChain
- Integrated sentence-transformers for embeddings
- Created background processing with Celery
- Added document status tracking (uploading, processing, completed, failed)
- Implemented document re-embedding functionality
- Added file storage (configurable to keep/delete originals)

**Backend files created/updated**:
- [backend/app/schemas/document.py](backend/app/schemas/document.py) - Document schemas
- [backend/app/services/embedding_service.py](backend/app/services/embedding_service.py) - Embedding generation
- [backend/app/services/document_service.py](backend/app/services/document_service.py) - Document processing
- [backend/app/workers/tasks.py](backend/app/workers/tasks.py) - Celery tasks (updated)
- [backend/app/api/documents.py](backend/app/api/documents.py) - Document endpoints (updated)

**Key features implemented**:
- Async file upload with FastAPI
- PDF text extraction with page numbers
- CSV parsing row-by-row
- Semantic chunking (configurable size/overlap)
- Batch embedding generation with sentence-transformers/all-MiniLM-L6-v2
- Storage in pgvector database
- Background processing with Celery (max 3 retries)
- Error handling and status reporting
- Document deletion (with file cleanup)
- Re-processing capability for failed documents

**API Endpoints**:
- POST /api/documents/models/{model_id}/documents - Upload document (Admin)
- GET /api/documents/models/{model_id}/documents - List documents
- GET /api/documents/documents/{id} - Get document details
- DELETE /api/documents/documents/{id} - Delete document (Admin)
- POST /api/documents/documents/{id}/reprocess - Reprocess document (Admin)

**Processing Pipeline**:
1. Upload file ‚Üí Create document record
2. Save file (if KEEP_ORIGINAL_FILES=true)
3. Queue Celery task
4. Parse file (PDF/CSV)
5. Chunk text semantically
6. Generate embeddings (batch)
7. Store chunks + embeddings in pgvector
8. Update document status

---

#### ‚úÖ Task 8: Implement RAG chat system with citations and WebSocket
**Status**: Completed

**What was done**:
- Implemented complete RAG (Retrieval-Augmented Generation) system
- Created vector similarity search using pgvector cosine distance
- Integrated multiple LLM providers (Ollama, OpenAI, Anthropic, Custom)
- Implemented streaming and non-streaming chat responses
- Added WebSocket support for real-time streaming
- Implemented chat session management
- Added chat history with context awareness
- Implemented source citations with similarity scores
- Created comprehensive chat API endpoints

**Backend files created/updated**:
- [backend/app/schemas/chat.py](backend/app/schemas/chat.py) - Chat schemas
- [backend/app/services/rag_service.py](backend/app/services/rag_service.py) - RAG logic
- [backend/app/services/llm_service.py](backend/app/services/llm_service.py) - LLM integrations
- [backend/app/api/chat.py](backend/app/api/chat.py) - Chat API endpoints (updated)

**Key features implemented**:
- **Vector Search**:
  - Cosine similarity search with pgvector
  - Configurable top-k retrieval (default 5 chunks)
  - Similarity threshold filtering (0.3 minimum)
  - Context building from retrieved chunks

- **LLM Integration**:
  - Ollama support (default, local)
  - OpenAI API support (GPT-3.5, GPT-4)
  - Anthropic Claude support
  - Custom provider support
  - Both streaming and non-streaming modes
  - Automatic API key decryption

- **RAG Pipeline**:
  1. Generate query embedding
  2. Search similar chunks in pgvector
  3. Build context from top-k results
  4. Include chat history for continuity
  5. Construct optimized prompt
  6. Generate LLM response
  7. Return with source citations

- **Chat Management**:
  - Session-based conversations
  - Automatic session creation
  - Chat history persistence
  - Context-aware responses (last 5 messages)
  - Message storage with sources

- **WebSocket**:
  - Token-based authentication
  - Real-time streaming responses
  - Bi-directional communication
  - Error handling and reconnection
  - Source citation delivery
  - Message acknowledgments

**API Endpoints**:
- POST /api/chat/chat - Chat with RAG (non-streaming)
- WS /api/chat/ws?token={token} - WebSocket streaming chat
- GET /api/chat/sessions - Get user's chat sessions
- GET /api/chat/sessions/{id}/messages - Get session messages
- DELETE /api/chat/sessions/{id} - Delete session

**WebSocket Message Types**:
- `user_message` - User message saved
- `sources` - Retrieved source citations
- `stream_start` - Response streaming begins
- `stream_chunk` - Response content chunk
- `stream_end` - Response streaming complete
- `message_saved` - Assistant message saved
- `error` - Error occurred

**RAG Prompt Template**:
```
You are a helpful AI assistant. Answer based on the provided context.

Context from knowledge base:
[Source citations with content]

Previous conversation:
[Last 5 messages]

Instructions:
1. Answer using ONLY the provided context
2. If context doesn't have the info, say so honestly
3. Include specific references to sources
4. Be concise and accurate

User Question: {query}

Assistant Answer:
```

**Source Citation Format**:
```json
{
  "document_id": 123,
  "document_name": "example.pdf",
  "chunk_content": "Relevant excerpt...",
  "page": 5,
  "similarity_score": 0.87
}
```

---

#### ‚úÖ Task 9: Implement admin dashboard UI
**Status**: Completed

**What was done**:
- Created complete admin dashboard with navigation
- Implemented model management UI with create/delete
- Implemented document management UI with upload
- Implemented user management UI with role changes
- Added responsive layout with sidebar navigation
- Integrated all admin features with backend APIs

**Frontend files created**:
- [frontend/src/components/AdminLayout.tsx](frontend/src/components/AdminLayout.tsx) - Admin layout wrapper with sidebar
- [frontend/src/app/admin/page.tsx](frontend/src/app/admin/page.tsx) - Admin dashboard homepage with stats
- [frontend/src/app/admin/models/page.tsx](frontend/src/app/admin/models/page.tsx) - Model CRUD interface
- [frontend/src/app/admin/documents/page.tsx](frontend/src/app/admin/documents/page.tsx) - Document upload and management
- [frontend/src/app/admin/users/page.tsx](frontend/src/app/admin/users/page.tsx) - User management interface

**Frontend files updated**:
- [frontend/src/app/dashboard/page.tsx](frontend/src/app/dashboard/page.tsx) - Added links to chat and admin

**Key features implemented**:
- **AdminLayout Component**:
  - Authentication check (redirect non-admins)
  - Sidebar navigation with active state
  - User profile display with logout
  - Responsive design for mobile/desktop
  - Dark mode support

- **Admin Dashboard**:
  - Statistics cards (users, models, documents)
  - Quick action buttons
  - Activity overview
  - System status

- **Model Management**:
  - Create model with modal form
  - LLM provider selection (Ollama, OpenAI, Anthropic, Custom)
  - Model name and configuration
  - API key input for external providers
  - Delete models with confirmation
  - Grid display with model cards

- **Document Management**:
  - Model selection dropdown
  - File upload with drag-and-drop
  - File validation (PDF/CSV, 250MB limit)
  - Document table with status badges
  - Document deletion
  - Real-time status updates

- **User Management**:
  - User table with email, name, role
  - Inline role change dropdown (except superadmin)
  - Active/Inactive toggle button
  - User deletion (except superadmin)
  - Created date display
  - Role-based protection

**UI Components & Patterns**:
- Toast notifications for all actions
- Loading states for async operations
- Confirmation dialogs for destructive actions
- Error handling with user feedback
- Consistent styling with TailwindCSS
- Dark mode throughout

---

#### ‚úÖ Task 10: Implement chat interface UI
**Status**: Completed

**What was done**:
- Created complete chat interface with WebSocket streaming
- Implemented real-time message streaming
- Added source citations display
- Integrated markdown rendering for responses
- Created model selection dropdown
- Added chat history display
- Implemented message input with send functionality

**Frontend files created**:
- [frontend/src/app/chat/page.tsx](frontend/src/app/chat/page.tsx) - Chat interface with streaming

**Key features implemented**:
- **WebSocket Integration**:
  - Automatic connection on mount
  - Token-based authentication
  - Real-time streaming response handling
  - Reconnection logic
  - Error handling and recovery

- **Chat Interface**:
  - Model selection dropdown (accessible models)
  - Message display with role differentiation
  - User messages (right-aligned, blue)
  - Assistant messages (left-aligned, gray)
  - Markdown rendering with react-markdown
  - Code syntax highlighting support

- **Source Citations**:
  - Display below assistant messages
  - Document name and page number
  - Similarity score badge
  - Expandable chunk content preview
  - Styled as info cards

- **Message Input**:
  - Textarea with auto-resize
  - Send button with loading state
  - Enter to send, Shift+Enter for newline
  - Disabled while streaming
  - Character count (optional)

- **UX Features**:
  - Auto-scroll to bottom on new messages
  - Loading indicator while streaming
  - Toast notifications for errors
  - Empty state with instructions
  - Responsive layout

**WebSocket Message Handling**:
- `user_message` - Acknowledge user message sent
- `sources` - Display source citations
- `stream_start` - Show loading indicator
- `stream_chunk` - Append to message content
- `stream_end` - Finalize message display
- `message_saved` - Update message ID
- `error` - Show error toast

---

#### ‚úÖ Task 11: Implement file upload in chat
**Status**: Completed

**What was done**:
- Added file upload endpoint to chat API
- Implemented file upload button in chat interface
- Added file validation (type and size)
- Integrated with document processing pipeline
- Added visual feedback for upload status

**Backend files updated**:
- [backend/app/api/chat.py](backend/app/api/chat.py) - Added POST /api/chat/upload endpoint

**Frontend files updated**:
- [frontend/src/app/chat/page.tsx](frontend/src/app/chat/page.tsx) - Added file upload UI

**Key features implemented**:
- **File Upload Endpoint**:
  - Accepts PDF, CSV, and TXT files
  - Validates user access to model
  - Processes file in background with Celery
  - Returns immediate response with processing status
  - File size limit: 250MB (configurable)

- **Chat UI Integration**:
  - File upload button (üìé) in chat input area
  - Hidden file input with proper accept attributes
  - Visual feedback during upload (‚è≥)
  - Success/error toast notifications
  - System message in chat confirming upload
  - Disabled state management during upload

- **User Flow**:
  1. User clicks üìé button in chat
  2. File picker opens (PDF/CSV/TXT only)
  3. File is validated (type and size)
  4. File uploads to server
  5. System message appears in chat
  6. File processes in background
  7. User can immediately ask questions
  8. Embeddings become available within seconds

**Validation**:
- Allowed file types: PDF, CSV, TXT
- Maximum file size: 250MB
- Model access verification
- User authentication required

---

#### ‚úÖ Task 12: Write deployment documentation
**Status**: Completed

**What was done**:
- Created comprehensive deployment guide
- Documented development setup process
- Detailed production deployment steps
- Included security best practices
- Added monitoring and maintenance procedures
- Provided troubleshooting guide
- Created backup and recovery procedures

**Documentation file created**:
- [DEPLOYMENT.md](DEPLOYMENT.md) - Complete deployment guide

**Key sections included**:
- **Prerequisites**: System requirements, software installation
- **Architecture Overview**: Service descriptions, network architecture, data flow
- **Development Setup**: Step-by-step local development setup
- **Production Deployment**: Server preparation, Docker configuration, nginx setup, SSL
- **Environment Variables**: Complete reference for all configuration options
- **Database Setup**: PostgreSQL configuration, migrations, backups
- **Security Configuration**: Passwords, permissions, firewall, rate limiting, HTTPS
- **Monitoring and Maintenance**: Health checks, logs, resource monitoring, updates
- **Troubleshooting**: Common issues and solutions for all components
- **Backup and Recovery**: Automated backup script, manual backup, recovery procedures
- **Production Checklist**: Complete pre-deployment verification list

**Deployment features covered**:
- Docker Compose for development and production
- Nginx reverse proxy configuration
- SSL/TLS with Let's Encrypt
- PostgreSQL with pgvector
- Redis configuration
- Ollama model setup
- Celery worker deployment
- Environment variable management
- Security hardening
- Performance optimization
- Log management
- Backup automation
- Health monitoring
- Troubleshooting guides

---

**Next steps**:
- Add session management UI (view/delete past chats)
- Implement model assignment UI in admin panel
- Add file upload progress indicator
- Create user documentation/guide

---

## Project Structure

```
llm-rag/
‚îú‚îÄ‚îÄ backend/                 # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/            # API routes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ core/           # Configuration, security
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/         # Database models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas/        # Pydantic schemas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/       # Business logic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ workers/        # Celery tasks
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ main.py         # FastAPI app entry
‚îÇ   ‚îú‚îÄ‚îÄ alembic/            # Database migrations
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ frontend/               # Next.js application
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/           # App router pages
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/    # React components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lib/           # Utilities, API clients
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/         # Custom hooks
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ types/         # TypeScript types
‚îÇ   ‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml      # Development environment
‚îú‚îÄ‚îÄ .env.example           # Environment variables template
‚îú‚îÄ‚îÄ DEPLOYMENT.md          # Deployment guide
‚îî‚îÄ‚îÄ claude.md              # This file
```

---

## Environment Variables

### Backend (.env)
```
# Database
DATABASE_URL=postgresql://user:password@postgres:5432/llmrag

# Redis
REDIS_URL=redis://redis:6379/0

# Security
SECRET_KEY=your-secret-key
SUPERADMIN_EMAIL=admin@example.com
SUPERADMIN_PASSWORD=changeme

# File Storage
KEEP_ORIGINAL_FILES=true
MAX_FILE_SIZE_MB=250

# Ollama
OLLAMA_BASE_URL=http://ollama:11434
```

### Frontend (.env.local)
```
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_WS_URL=ws://localhost:8000
NEXTAUTH_SECRET=your-nextauth-secret
NEXTAUTH_URL=http://localhost:3000
```

---

## Database Schema (Planned)

### Tables
- **users**: id, email, hashed_password, full_name, role, is_active, created_at
- **models**: id, name, description, llm_provider, llm_model_name, api_key_encrypted, created_by, created_at
- **model_user_access**: model_id, user_id (many-to-many)
- **documents**: id, model_id, filename, file_path, file_size, status, uploaded_by, created_at
- **document_chunks**: id, document_id, model_id, content, embedding (vector), metadata, chunk_index
- **chat_sessions**: id, user_id, model_id, created_at, updated_at
- **chat_messages**: id, session_id, user_id, role (user/assistant), content, sources (jsonb), created_at

---

## API Endpoints (Planned)

### Authentication
- POST /api/auth/signup - User registration
- POST /api/auth/login - User login
- POST /api/auth/refresh - Refresh token
- GET /api/auth/me - Get current user

### Users (Admin only)
- GET /api/users - List users
- GET /api/users/{id} - Get user
- PATCH /api/users/{id} - Update user (promote to admin)
- DELETE /api/users/{id} - Delete user

### Models
- POST /api/models - Create model (Admin)
- GET /api/models - List accessible models
- GET /api/models/{id} - Get model details
- PATCH /api/models/{id} - Update model (Admin)
- DELETE /api/models/{id} - Delete model (Admin)
- POST /api/models/{id}/users - Assign users to model (Admin)

### Documents
- POST /api/models/{id}/documents - Upload document (Admin, WebSocket progress)
- GET /api/models/{id}/documents - List documents
- DELETE /api/documents/{id} - Delete document (Admin)

### Chat
- WS /api/chat/ws - WebSocket endpoint for chat
- GET /api/chat/history - Get chat history
- POST /api/chat/upload - Upload file in chat

---

## Notes & Decisions

- **Embedding Model**: Using sentence-transformers/all-MiniLM-L6-v2 (384 dimensions, fast, good quality)
- **Semantic Chunking**: Will use LangChain's SemanticChunker with sentence-transformers
- **API Key Storage**: Will encrypt LLM provider API keys using Fernet (cryptography library)
- **WebSocket**: Using FastAPI WebSocket for both upload progress and chat streaming
- **Celery**: For background document processing (parsing, chunking, embedding)
- **File Storage**: Configurable via KEEP_ORIGINAL_FILES env var

---

## Testing Strategy

- Backend: pytest with test database
- Frontend: Jest + React Testing Library
- E2E: Playwright (optional)
- Load testing: Locust for concurrent chat sessions

---

## Deployment Checklist

- [ ] Configure production environment variables
- [ ] Set up PostgreSQL with pgvector extension
- [ ] Set up Redis instance
- [ ] Set up Ollama or LLM provider
- [ ] Build Docker images
- [ ] Configure Docker volumes for file storage
- [ ] Set up reverse proxy (nginx)
- [ ] Configure SSL certificates
- [ ] Initialize superadmin user
- [ ] Run database migrations
- [ ] Test WebSocket connections
- [ ] Monitor resource usage

---

---

## Current Status

### ‚úÖ Completed
- Project structure and documentation
- Docker Compose configuration with all services
- Backend FastAPI application with database models
- Frontend Next.js application with basic structure
- Database migration setup with Alembic
- Celery worker configuration
- **Authentication system with JWT**
- **User management and RBAC**
- **Login/Signup/Dashboard frontend pages**
- **Model (collection) CRUD with access control**
- **Document upload and embedding pipeline**
- **RAG chat system with vector search**
- **WebSocket for streaming chat**
- **Chat history and session management**
- **Source citations with similarity scores**
- **Admin dashboard UI (models, documents, users)**
- **Chat interface UI with WebSocket streaming**
- **File upload in chat for users**

### üöß In Progress
- None currently

### ‚è≥ Pending
- Session management UI (view/delete past chats)
- Model user assignment UI in admin panel
- User documentation/guide
- Testing suite (unit, integration, e2e)

---

## Summary

The LLM RAG Chatbot application is now **feature-complete** for core functionality:

**Backend (FastAPI)**:
- Complete authentication system with JWT and role-based access control
- Model (collection) management with multi-provider LLM support
- Document processing pipeline with semantic chunking and embedding
- RAG system with pgvector similarity search
- WebSocket streaming chat with source citations
- Background processing with Celery

**Frontend (Next.js)**:
- Authentication pages (login, signup, dashboard)
- Admin panel with full CRUD for models, documents, and users
- Real-time chat interface with WebSocket streaming
- Source citation display
- File upload in chat (PDF, CSV, TXT)
- Responsive design with dark mode

**Ready for**:
- Development testing with Docker Compose
- Additional features (session management UI, model assignment UI)
- Production deployment documentation

---

*Last updated: 2026-01-17*
